## HashMap

首先，在jdk1.7和1.8当中，hashmap结构是不一样的

在1.7中，hashmap的结构为数组加链表、1.8中为数组+链表+红黑树（根据加载因子0.75，当元素个数达到8时会转为红黑树，当减少到6个时会转为链表）。数组里面存的都是key-value这样entry对象（在1.8中为node）。每一个节点都保存了key、value、hash、以及下个节点next。在put的时候，会根据key的hash计算index。因为存在概率性问题，可能会存在key的hash相等的情况，所以链表出现了。hashmap 会把hash值相等的key以链表的方式存在数组的某个位置。

链表插入的方式，在1.7使用的是头插，1.8使用的尾插。

头插：就是新来的值会取代原来的值，原有的值会顺序推到链表中。然而在hashmap扩容的时候，hashmap会根据当前容量和加载因子来判断什么时候扩容。扩容会先创建一个长度为原数组两倍的空数组，因为新数组的长度发生的改变，所以在拷贝元素的时候会重新计算每个key的hash（rehash）。所以原先在某个位置的key在新数组中位置可能会发生变化。

然后再多线程的环境下，在rehash的时候，可能会发生所有key都已经存进去而扩容还没有完成，对于有相同hash值的key来说就有可能会出现环形链表，然后再取数据的时候出现**死循环**。

使用头插会改变链表的顺序，但是使用尾插，在扩容时，会保持链表元素的原本顺序，就不会出现环形链表了。

## ConcurrentHashMap

#### HashTable 不能存 null？

HashTable不允许键或值为null，hashmap允许；因为HashTable使用的是**安全失败机制**（fail-safe），这种机制会使你此次读到的数据不一定是最新的。如果你是用null，就会使得其无法判断对应的key是不存在还是空，因为无法再次调用contain（key）来对key是否存在进行判断，ConcurrentHashMap同理。

#### **安全失败机制**（fail-safe）

采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。所以在修改原集合的时候并不会触发 ConcurrentModificationException。

虽然避免了异常，但是迭代器在开始遍历到结束，中间原集合修改，迭代器并不能感知。

#### hashTable 和 HashMap比较

**实现方式不同**：HashTable 是 Dictionary，HashMap 是 AbstractMap

**初始化容量不同**：HashTable 11，HashMap 16，加载因子都是0.75

**扩容机制不同**：当容量大于 当前容量 * 加载因子时，HashTable 扩容为当前容量*2 +1，HashMap为当前容量两倍

**迭代器不同**：HashTable 的 Enumerator 不是 fail-fast。HashMap 中 Iterator 迭代器是fail-fast

#### fail-fast：快速失败

java集合中的一种机制，在使用迭代器对集合进行遍历的时，如果遍历过程中对集合的内容进行了修改（增删改），则会抛出异常。

在HashMap中维护了一个modCount用来记录在遍历期间如果内容发生变化化，就会改变modCount的值。每当迭代器使用hasNext()和next()方法之前都会判断 modCount的值是否为expectedmodCount。是的话返回遍历，不是就会抛出异常 ConcurrentModificationException。

但是这个异常不能用来在并发编程下作为条件。可以用于并发检测修改的bug。

#### 为什么使用ConcurrentHahsMap

因为HashMap 是线程不安全的。

1. 可以使用Collections.synchronized(map)创建一个线程安全的map集合，
2. 使用HashTable。
3. 使用ConcurrentHashMap

不过出于线程并发的原因，一般都是使用ConcurrentHashMap。因为使用 Collections.synchronized(map) 得到的synchronizedMap，对map进行操作的时候就会对方法上锁。

HashTable它在对数据操作的时候就都会上锁，所以效率很低。

##### 原理

首先，数据结构和hashmap差不多，不同点是，它使用了volatile修饰了它数据的value和next节点。

jdk1.7中，采用的是**分段锁**技术。每个segment都继承了Reentrantlock，不会像hashtable 那样不管是put还是get都会加锁。理论上ConcurrentHahsMap支持 segment数组数量的线程并发，没一个线程访问一个segment时并不会影响其他的segment。

put的时候

1、先尝试获取锁，如果失败则scanAndLockForPut（）自旋获取锁。如果自旋达到一定次数还没获取锁，则改为阻塞获取锁，保证能获取到锁。

get

因为HashEntry中的value被volatile修饰，保证了内存可见，每次都能获取到最新值。所以get操作不要加锁，非常高效。

**因为1.7使用的是数组+链表，去查询的时候还是得遍历链表。查询速度效率很低。在1.8之后。**

首先抛弃了分段锁，采用 cas + synchronized 来保证并发。然后引入了红黑树，当链表达到一定数量（默认8），会转为红黑树。

##### put

1、根据key计算hash

2、判断是否需要初始化

3、根据key的hash定位到node，判断是否为null，为空则可以写入。利用自旋，保证成功

4、如果当前位置的 hash = MOVE == -1，则需要扩容

5、如果都不满足，说明定位到node有值，然后使用synchronized锁写入数据

6、如果存入的数据数量满足转树，则链表转红黑树

##### CAS

乐观锁的一种实现方式，一种轻量级锁。线程在读取数据时不加锁，在写数据时，会先比较原值是否修改，没有修改则写入，如果被修改，则重新读取直到成功。（一个缺点，消耗cpu性能）。

但是在使用CAS的时候可能出现ABA问题，也就是我在比较之前，可能数据被修改了多次了，然后最终的结果和然来的值还是一样，CAS只保证了结果的准确，并不能保证过程的准确性，对于像转账的业务，这种情况是错误的。

##### 怎么避免ABA?

使用版本号或者时间戳的方式

##### synchronized 1.8 的优化

针对synchronized获取锁的方式，JVM采用了锁升级的方式，就是先使用偏向锁优先同一线程获取锁，如果失败就升级为 CAS 轻量级锁，如果失败就会短暂自旋，防止线程被体统挂起。最后再失败就升级为重量级锁了。所以1.8之后使用synchronized性能并不会很差。

##### get

1、根据key的hash寻址，如果就在bucket上，就直接返回

2、如果是在红黑树上就根据数的方式取值

3、如果再链表上没遍历链表取值

## redis

redis在网络请求模块是单线程，其他模块仍用了多线程

### redis快速？

1、单线程，避免了不必要的上下文切换和竞争条件

2、觉大部分请求都是基于内存的

3、非阻塞多路复用IO









1.说一下之前做过的项目
2.Spring Bean的注入过程
3.Java8的新特性 流式处理的性能
4.Synchronized和lock底层实现原理 分别是什么层面的 jdk or JVM?
5.Synchronized 锁不同的作用域如何实现？锁升级过程
6.CAS 乐观锁 自旋效率 高并发场景阻塞怎么解决
7.线程池
8.JVM调优基本步骤 CPU100%问题怎么解决
9.MySQL 慢查询优化、索引结构，B树和B+树的区别，MyIsam和InnoDb区别,一张表最多可以建多少个索引？
10.Redis:为什么选择使用Redis？为什么这么快？一定是单线程的吗？如何保证高可用？集群机制 缓存击穿和缓存穿透
11.Spring的优点是什么？AOP和IOC
12.Dubbo的调用链路，服务暴露过程
13.了解哪些设计模式？
14.项目中如何保证幂等性，如何避免重复消费
15.分布式锁如何实现的？
16.离职的原因？
17.职业规划？
问题扩展：
Redis的集群 主备同步 启动数据化初始化 Rewrite
SpringCloud Hystrix bus